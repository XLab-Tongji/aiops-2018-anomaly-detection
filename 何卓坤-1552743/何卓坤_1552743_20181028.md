# Report

Oct 28th He Zhuokun



##System Log Analysis for Anomaly Detection

The large-scale and parallel nature of mordern systems makes system behaviours too complex to comprehend by each single developer. Mordern systems are generating tons of logs, for example, at a rate of about 50 gigabytes per hour. Large-scale systems are typically built with different fault tolerant mechanisms employed. So automated log analysis methods for anomaly detection are highly in demand.

The paper introduces two broad categories: supervised anomaly detection and unsupervised anomaly detection.

| Supervised | Unsupervised |
| :--------- | ------------ |
| Logisitic Regression | Log Clustering |
| Decision Tree | PCA |
| SVM | Invariant Mining |

In conclusion, supervised anomaly detection methods achieve higher precision than that of unsupervised anomaly detection. And anomaly detection woth sliding windows can achieve higher accuracy than that of fixed windows.  

[*System Log Analysis for Anomaly Detection*](https://www.semanticscholar.org/paper/Experience-Report%3A-System-Log-Analysis-for-Anomaly-He-Zhu/2c1ed7e32a85d72fb270ebd07a45641acfba02a9)

## Non deep learning

The main four steps of anomaly detection are log collection, log parsing,   feature extraction and anomaly detection.

![Framework of anomaly detection](framework.png)



### Log Parsing

- Clustering-bases: distance between logs are calculate first, and clustering techniques are often employed to group logs into different clusters in the next step.
- Heuristic-based: occurrences of each word on each log position are counted. Next, frequent words are selected and composed as the event candidates. Finally, some candidates are chosen to be the log events.

### Feature Extraction

Based on timestamp, which records the occurence time of each log:

- Fixed windows
- Sliding windows

Based on identifiers, utilized to mark different execution paths in some log data, instead of the timestamp:

- Session window

### Supervised Anomaly Detection 

- Logistic Regression

  To detect anomalies, an event count vector is constructed from each log sequence, and every event count vector together with its label are called an instance.

- Decision Tree

![decison tree](decision.png)

- SVM

  The training instances are event count vectors together with their labels. In anomaly detection via SVM, if a new instance is located above the hyperplane, it would be reported as an anomaly.

### Unsupervised Anomaly Detection

- Log Clustering

  This method is used to identify online system problems. It requires two training phases, namely knowledge base initialization phase and online learning phase. Knowledge base initialization phase contains three steps: log vectorization, log clustering, representative vector extraction. Online learning phase is used to further adjust the cluster constructed in knowledge base initialization phase.

- PCA

  Employing PCA, two subspace are generated, namely normal space S~n~ and anomaly space S~a~ . S~n~  is constructed by the ﬁrst k principal components and S~n~  is constructed by the remaining (n−k), where n is the original dimension. Then, the projection y a = (1−PP^T^ )y of an event count vector y to S~a~ is calculated, where P = [v 1, v 2, . . . , v k, ] is the ﬁrst k principal components. If the length of y~a~ is larger than a threshold, the corresponding event count vector will be reported as an anomaly. 

  ![PCA](pca.png)

- Invariants Mining

  Program Invariants are the linear relationships that always hold during system running even with various inputs and under different workloads.

  ![invariant mining](invariants.png)

  In this execution ﬂow, the system generates a log message at each stage from A to G. Assuming that there are plenty of instances running in the system and they follow the program execution ﬂow in Figure 4, the following equations would be valid:

  n (A) = n (B)

  n (B) = n (C) + n (E) + n (F)

  n (C) = n (D)

  n (G) = n (D) + n (E) + n (F)

  Intuitively, Invariants mining could uncover the linear relationships between multiple log events that represent system normal execution behaviors. Linear relationships prevail in real-world system events. 

  Invariants mining, which aims at ﬁnding invariants (i.e., linear relationships), contains three steps. 

  - Firstly, the invariant space is estimated using singular value decomposition, which determines the amount r of invariants that need to be mined in the next step. 
  - Secondly, this method ﬁnds out the invariants by a brute force search algorithm. 
  - Finally, each mined invariant candidate is validated by comparing its support with a threshold.


## Deep Learning

[*Anomaly Detection and Diagnosis from System Logs through Deep Learning*](https://www.cs.utah.edu/~lifeifei/papers/deeplog.pdf)

The architecture of DeepLog is composed of the log key anomaly detection model, the parameter value anomaly detection model, and the workflow model to diagnose detected anomalie.

![deeplog](deeplog.png)

- Training stage

  Training data for DeepLog are log entries from normal system execution path. Each log entry is parsed to a log key and a parameter value vector. The log key sequence parsed from a training log ﬁle is used by DeepLog to train a log key anomaly detection model, and to construct system execution workﬂow models for diagnosis purposes. 

- Detection stage

  A newly arrived log entry is parsed into a log key and a parameter value vector. DeepLog ﬁrst uses the log key anomaly detection model to check whether the imcoming log key is normal. 

### Anomaly Detection

- Traditional N-gram language model
- LSTM