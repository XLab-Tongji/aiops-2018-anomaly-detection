{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以识别手写数字为例，构建两层LSTM网络，实验主为 explorer 其内部黑盒结构，使用tensorflow API\n",
    "  #### 将原来 784 维的像素点图，按行序输入，序列长fix 为 28 \n",
    "  #### 并行的批次超参在训练和测试时consistant 5\n",
    "  #### LSTM内隐藏前馈层神经元out 各层都 fix 256\n",
    "  #### 多分类激活用softmax\n",
    "  #### 损失用交叉熵，其产生背景及原理此处不细数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-f92f28c3059b>:17: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting E:\\GitHub\\example-notebook\\MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting E:\\GitHub\\example-notebook\\MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting E:\\GitHub\\example-notebook\\MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting E:\\GitHub\\example-notebook\\MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "(55000, 784)\n",
      "WARNING:tensorflow:From <ipython-input-1-f92f28c3059b>:55: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "step 50,train_cost=0.110769,acc=0.640000,test_cost=0.089475,test_acc=0.704000; pass 16.19688391685486 s\n",
      "step 100,train_cost=0.048572,acc=0.810000,test_cost=0.052365,test_acc=0.828000; pass 13.141026735305786 s\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib import rnn\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  \n",
    "\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "\n",
    "mnist = input_data.read_data_sets(r'..\\MNIST_data',one_hot=True)\n",
    "print(mnist.train.images.shape)\n",
    "\n",
    "\n",
    "#####################\n",
    "# (55000, 784)\n",
    "# [Finished in 11.4s]\n",
    "#####################\n",
    "\n",
    "\n",
    "\n",
    "#设置模型的超参数: 输入输出，层数，每层的隐藏节点数，最后的分类数\n",
    "\n",
    "lr= 1e-3\n",
    "input_size=28\n",
    "timestep_size=28\n",
    "hidden_size=256\n",
    "layer_num=2\n",
    "class_num=10\n",
    "cell_type=\"lstm\"\n",
    "\n",
    "X_input = tf.placeholder(tf.float32,[None,784])\n",
    "y_input = tf.placeholder(tf.float32,[None,class_num])\n",
    "\n",
    "#训练和测试的时候，我们想用不同的 batch_size,所以采用占位符的方式\n",
    "batch_size=tf.placeholder(tf.int32,[]) \n",
    "keep_prob=tf.placeholder(tf.float32,[])\n",
    "\n",
    "\n",
    "X = tf.reshape(X_input,[-1,28,28])\n",
    "\n",
    "\n",
    "def lstm_cell(cell_type,num_nodes,keep_prob):\n",
    "\tcell=tf.contrib.rnn.BasicLSTMCell(num_nodes)\n",
    "\tcell=tf.contrib.rnn.DropoutWrapper(cell,output_keep_prob=keep_prob)\n",
    "\treturn cell\n",
    "\n",
    "mlstm_cell = tf.contrib.rnn.MultiRNNCell([lstm_cell(cell_type,hidden_size,keep_prob) for _ in range(layer_num)],state_is_tuple=True)\n",
    "\n",
    "\n",
    "\n",
    "#用全零来初始化state\n",
    "init_state = mlstm_cell.zero_state(batch_size,dtype=tf.float32)\n",
    "\n",
    "## 利用cell class 的__call__()函数，\n",
    "outputs=list()\n",
    "state = init_state\n",
    "with tf.variable_scope('RNN'):\n",
    "\tfor timestamp in range(timestep_size):\n",
    "\t\t(cell_output,state) = mlstm_cell(X[:,timestamp,:],state)\n",
    "\t\toutputs.append(cell_output)\n",
    "\n",
    "h_state = outputs[-1]\n",
    "\n",
    "\n",
    "import time \n",
    "# 开始训练和测试\n",
    "\n",
    "W = tf.Variable(tf.truncated_normal([hidden_size,class_num],stddev=0.1),dtype=tf.float32)\n",
    "bias = tf.Variable(tf.constant(1/class_num,shape=[class_num]),dtype=tf.float32)\n",
    "\n",
    "y_pre = tf.nn.softmax(tf.matmul(h_state,W)+bias)\n",
    "\n",
    "# 损失和评估函数\n",
    "\n",
    "cross_entropy = -tf.reduce_mean(y_input*tf.log(y_pre))\n",
    "train_op = tf.train.AdamOptimizer(lr).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_pre,1),tf.argmax(y_input,1))\n",
    "accuracy= tf.reduce_mean(tf.cast(correct_prediction,\"float\"))\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "time0 = time.time()\n",
    "\n",
    "for i in range(100):\n",
    "\t_batch_size=100\n",
    "\tX_batch,y_batch = mnist.train.next_batch(batch_size=_batch_size)\n",
    "\tcost,acc,_ = sess.run([cross_entropy,accuracy,train_op],feed_dict={X_input:X_batch,y_input:y_batch,keep_prob:1.0,batch_size:_batch_size})\n",
    "\tif (i+1) % 50 ==0:\n",
    "\t\t#分 5 次进行批处理\n",
    "\t\ttest_acc = 0.0\n",
    "\t\ttest_cost = 0.0\n",
    "\t\tN = 10\n",
    "\t\tfor j in range(N):\n",
    "\t\t\tX_batch,y_batch = mnist.train.next_batch(batch_size=_batch_size)\n",
    "\t\t\t_cost,_acc = sess.run([cross_entropy,accuracy],feed_dict={X_input:X_batch,y_input:y_batch,keep_prob:1.0,batch_size:_batch_size})\n",
    "\t\t\ttest_cost += _cost\n",
    "\t\t\ttest_acc += _acc\n",
    "\t\tprint(\"step {},train_cost={:.6f},acc={:.6f},test_cost={:.6f},test_acc={:.6f}; pass {} s\".format(i+1,cost,acc,test_cost/N,test_acc/N,time.time()-time0))\n",
    "\t\ttime0 = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 784) (5, 10)\n"
     ]
    }
   ],
   "source": [
    "_batch_size=5\n",
    "X_batch,y_batch = mnist.test.next_batch(_batch_size)\n",
    "print(X_batch.shape,y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_outputs.shape= (28, 5, 256)\n",
      "_state.shape= (2, 2, 5, 256)\n"
     ]
    }
   ],
   "source": [
    "_outputs,_state = np.array(sess.run([outputs,state],feed_dict={X_input:X_batch,y_input:y_batch,keep_prob:1.0,batch_size:_batch_size}))\n",
    "print(\"_outputs.shape=\",np.asarray(_outputs).shape)\n",
    "print(\"_state.shape=\",np.asarray(_state).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(mnist.train.labels[10:20])\n",
    "\n",
    "\n",
    "X3 = mnist.train.images[10]\n",
    "img3 = X3.reshape([28,28])\n",
    "plt.imshow(img3,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 1, 256)\n",
      "(28, 256)\n"
     ]
    }
   ],
   "source": [
    "X3.shape = [-1, 784]\n",
    "y_batch = mnist.train.labels[0]\n",
    "y_batch.shape = [-1, class_num]\n",
    "\n",
    "X3_outputs = np.array(sess.run(outputs, feed_dict={\n",
    "            X_input: X3, y_input: y_batch, keep_prob: 1.0, batch_size: 1}))\n",
    "print(X3_outputs.shape)\n",
    "X3_outputs.shape = [28, hidden_size]\n",
    "print(X3_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 28 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h_W, h_bias = sess.run([W, bias], feed_dict={\n",
    "            X_input:X3, y_input: y_batch, keep_prob: 1.0, batch_size: 1})\n",
    "h_bias = h_bias.reshape([-1, 10])\n",
    "\n",
    "bar_index = range(class_num)\n",
    "for i in range(X3_outputs.shape[0]):\n",
    "    plt.subplot(7, 4, i+1)\n",
    "    X3_h_shate = X3_outputs[i, :].reshape([-1, hidden_size])\n",
    "    pro = sess.run(tf.nn.softmax(tf.matmul(X3_h_shate, h_W) + h_bias))\n",
    "    plt.bar(bar_index, pro[0], width=0.2 , align='center')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
