### Report 20181212

Use logic regression，random forest，one-class-SVM，isolation forest for comparison. Random forest outperforms the rest.

##### Logistic Regression

```python
LogisticRegression(class_weight='balanced',n_jobs=2,C=1.0,penalty='l2')
```

| KPI_used | accuracy | F1__score | precision | recall |
| -------- | -------- | --------- | --------- | ------ |
| all      | 0.5498   | 0.6882    | 0.5265    | 0.9932 |



##### Random Forest

```python
RandomForestClassifier(n_estimators=15, max_features=int(math.sqrt(n_features)), max_depth=2*n_features, min_samples_split=2,bootstrap=True)
```

| KPI_used | accuracy | f1__score | precision | recall |
| -------- | -------- | --------- | --------- | ------ |
| all      | 0.9921   | 0.8164    | 0.8172    | 0.8156 |





##### Isolation Forest

```python
IsolationForest(n_estimators=10, behaviour='new', contamination=outliers_fraction, max_features=19,random_state=42, max_samples=256)
```

| KPI_used | accuracy | f1_score | precision | recall |
| -------- | -------- | -------- | --------- | ------ |
| all      | 0.5088   | 0.0825   | 0.1091    | 0.0663 |



##### One-class SVM

```
oc_svm=OneClassSVM(nu=outliers_fraction, kernel="rbf", gamma='scale')
```

| KPI_used | accuracy | F1_score | precision | recall |
| -------- | -------- | -------- | --------- | ------ |
| all      | 0.4619   | 0.4849   | 0.3200    | 1.0000 |

##### 
