{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入数据，以第一类KPI 为例，整理成tsfresh format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "train_data=pandas.read_csv('../../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timestamp', 'value', 'label', 'KPI ID'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 原始训练数据set的数据标签y与数据x分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_x=train_data.drop(['label'],axis=1)\n",
    "train_data_y=train_data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 取出一类KPI {采样频率为1分钟}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance1_x=list(train_data_x.groupby(by='KPI ID'))[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance1_y=train_data_y[:len(instance1_x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_interval=60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将数据x 整理tsfresh格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance1_x['timestamp']=pandas.Series(range(0,len(instance1_x)))\n",
    "instance1_x['KPI ID']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start,end=-1,0\n",
    "time_interval=60\n",
    "for i in range(len(instance1_x)//time_interval):\n",
    "    start=end+1\n",
    "    end=start+time_interval-1\n",
    "    if start>0:\n",
    "        ef=extract_features(instance1_x[start:end], column_id=\"KPI ID\", column_sort=\"timestamp\")\n",
    "        extracted_features=pandas.concat([extracted_features,ef],ignore_index=True)\n",
    "    else:    \n",
    "        extracted_features = extract_features(instance1_x[start:end], column_id=\"KPI ID\", column_sort=\"timestamp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "sys.path.append('../utils')\n",
    "import to_pickle as pk\n",
    "\n",
    "pk.save_as_pickle('extracted_features.pickle',{'extracted_features':extracted_features})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对第一类KPI 的异常标志y 进行time_interval内的加权平均[非0窗口即为发生异常]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features=pk.load_pickle('extracted_features.pickle')['extracted_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2142\n",
      "128562\n",
      "2143\n"
     ]
    }
   ],
   "source": [
    "instance1_y_=[]\n",
    "for i in range(len(instance1_y)//time_interval):\n",
    "    sum=0\n",
    "    for j in range(time_interval):\n",
    "        sum=sum+instance1_y[i*time_interval+j]\n",
    "    instance1_y_.append(sum/time_interval)  \n",
    "print(len(instance1_y_))    \n",
    "print(len(instance1_y))  \n",
    "sum=0\n",
    "for k in range(len(instance1_y)-time_interval*len(instance1_y_)):\n",
    "    sum=sum+instance1_y[time_interval*len(instance1_y_)+k]\n",
    "instance1_y_.append(sum/len(instance1_y)-time_interval*len(instance1_y_))  \n",
    "print(len(instance1_y_))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tsfresh import select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "\n",
    "impute(extracted_features)\n",
    "features_filtered = select_features(extracted_features,np.array(instance1_y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature=190"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2141, 190)\n",
      "(2141,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "trainX = np.array(features_filtered[:-2])\n",
    "trainX=trainX[:,:selected_feature]\n",
    "trainY = np.array(instance1_y_[:-2])\n",
    "trainY=trainY\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "u=len(trainY[np.where(trainY>0)])\n",
    "n=0\n",
    "trainX_copy=[]\n",
    "trainY_copy=[]\n",
    "for i in range(trainX.shape[0]):\n",
    "    if n<u  and trainY[i]==0:\n",
    "        trainX_copy.append(trainX[i])\n",
    "        trainY_copy.append(trainY[i])\n",
    "        n=n+1;\n",
    "    if trainY[i]!=0:\n",
    "        trainX_copy.append(trainX[i])\n",
    "        trainY_copy.append(trainY[i])\n",
    "trainX_copy=np.array(trainX_copy)\n",
    "trainY_copy = np.array(trainY_copy)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(trainX_copy, trainY_copy, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立两层Dense+Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "\n",
    "\n",
    "def buildModel(input_dim,drop=0.5,opt='adam',loss='mse',metrics=['accuracy']):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=256,activation='relu',input_dim=input_dim))\n",
    "    model.add(Dropout(drop))\n",
    "    model.add(Dense(units=256,activation='relu'))\n",
    "    model.add(Dropout(drop))\n",
    "    model.add(Dense(units=1,activation='sigmoid'))\n",
    "    model.compile(loss=loss,optimizer=opt,metrics=metrics)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               48896     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 114,945\n",
      "Trainable params: 114,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=buildModel(selected_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 361 samples, validate on 91 samples\n",
      "Epoch 1/100\n",
      "361/361 [==============================] - ETA: 10s - loss: 0.4554 - acc: 0.45 - ETA: 0s - loss: 0.5179 - acc: 0.3000 - 1s 2ms/step - loss: 0.4832 - acc: 0.3324 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 2/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.4682 - acc: 0.400 - ETA: 0s - loss: 0.3738 - acc: 0.480 - ETA: 0s - loss: 0.3432 - acc: 0.486 - 0s 358us/step - loss: 0.3426 - acc: 0.4848 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 3/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3149 - acc: 0.500 - ETA: 0s - loss: 0.3810 - acc: 0.459 - 0s 269us/step - loss: 0.3659 - acc: 0.4654 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 4/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.5372 - acc: 0.400 - ETA: 0s - loss: 0.3649 - acc: 0.453 - 0s 228us/step - loss: 0.3600 - acc: 0.4709 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 5/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.2229 - acc: 0.650 - ETA: 0s - loss: 0.3489 - acc: 0.500 - 0s 222us/step - loss: 0.3345 - acc: 0.5069 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 6/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3138 - acc: 0.450 - ETA: 0s - loss: 0.3302 - acc: 0.503 - 0s 279us/step - loss: 0.3359 - acc: 0.4986 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 7/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.2727 - acc: 0.650 - ETA: 0s - loss: 0.3353 - acc: 0.503 - 0s 261us/step - loss: 0.3412 - acc: 0.4958 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 8/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3592 - acc: 0.500 - ETA: 0s - loss: 0.3390 - acc: 0.510 - 0s 234us/step - loss: 0.3473 - acc: 0.4958 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 9/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.2349 - acc: 0.550 - ETA: 0s - loss: 0.3395 - acc: 0.503 - 0s 259us/step - loss: 0.3375 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 10/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3756 - acc: 0.500 - ETA: 0s - loss: 0.3341 - acc: 0.510 - 0s 220us/step - loss: 0.3469 - acc: 0.4958 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 11/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.2941 - acc: 0.550 - ETA: 0s - loss: 0.3470 - acc: 0.496 - 0s 222us/step - loss: 0.3387 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 12/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.2082 - acc: 0.600 - ETA: 0s - loss: 0.3332 - acc: 0.503 - 0s 210us/step - loss: 0.3383 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 13/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3305 - acc: 0.550 - ETA: 0s - loss: 0.3389 - acc: 0.490 - 0s 219us/step - loss: 0.3385 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 14/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.4094 - acc: 0.400 - ETA: 0s - loss: 0.3372 - acc: 0.471 - 0s 243us/step - loss: 0.3444 - acc: 0.4792 - val_loss: 0.3444 - val_acc: 0.4615\n",
      "Epoch 15/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3795 - acc: 0.300 - ETA: 0s - loss: 0.3568 - acc: 0.459 - 0s 272us/step - loss: 0.3568 - acc: 0.4626 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 16/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.4054 - acc: 0.400 - ETA: 0s - loss: 0.3221 - acc: 0.512 - 0s 251us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 17/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.4806 - acc: 0.400 - ETA: 0s - loss: 0.3269 - acc: 0.514 - 0s 225us/step - loss: 0.3371 - acc: 0.5042 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 18/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.2758 - acc: 0.550 - ETA: 0s - loss: 0.3337 - acc: 0.503 - 0s 258us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 19/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.4627 - acc: 0.450 - ETA: 0s - loss: 0.3566 - acc: 0.503 - 0s 254us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 20/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3775 - acc: 0.350 - ETA: 0s - loss: 0.3418 - acc: 0.485 - 0s 238us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 21/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.5363 - acc: 0.350 - ETA: 0s - loss: 0.3374 - acc: 0.496 - 0s 228us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 22/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3648 - acc: 0.550 - ETA: 0s - loss: 0.3276 - acc: 0.507 - 0s 220us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 23/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3499 - acc: 0.450 - ETA: 0s - loss: 0.3314 - acc: 0.507 - 0s 230us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 24/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3216 - acc: 0.550 - ETA: 0s - loss: 0.3415 - acc: 0.500 - 0s 233us/step - loss: 0.3400 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 25/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3427 - acc: 0.450 - ETA: 0s - loss: 0.3318 - acc: 0.500 - 0s 239us/step - loss: 0.3373 - acc: 0.5042 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 26/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.4936 - acc: 0.400 - ETA: 0s - loss: 0.3484 - acc: 0.500 - 0s 229us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 27/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.2511 - acc: 0.600 - ETA: 0s - loss: 0.3470 - acc: 0.485 - 0s 295us/step - loss: 0.3382 - acc: 0.5042 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 28/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3458 - acc: 0.550 - ETA: 0s - loss: 0.3567 - acc: 0.480 - 0s 229us/step - loss: 0.3407 - acc: 0.4986 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 29/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.2356 - acc: 0.450 - ETA: 0s - loss: 0.3324 - acc: 0.507 - 0s 220us/step - loss: 0.3367 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 30/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.5112 - acc: 0.350 - ETA: 0s - loss: 0.3382 - acc: 0.496 - 0s 232us/step - loss: 0.3427 - acc: 0.4986 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 31/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.4637 - acc: 0.300 - ETA: 0s - loss: 0.3364 - acc: 0.500 - 0s 232us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 32/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.2022 - acc: 0.750 - ETA: 0s - loss: 0.3415 - acc: 0.512 - 0s 288us/step - loss: 0.3446 - acc: 0.4986 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 33/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.4396 - acc: 0.350 - ETA: 0s - loss: 0.3305 - acc: 0.516 - 0s 279us/step - loss: 0.3345 - acc: 0.5069 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 34/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.2667 - acc: 0.500 - ETA: 0s - loss: 0.3367 - acc: 0.509 - 0s 219us/step - loss: 0.3380 - acc: 0.5042 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 35/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.4268 - acc: 0.400 - ETA: 0s - loss: 0.3412 - acc: 0.506 - 0s 210us/step - loss: 0.3397 - acc: 0.5042 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 36/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.6002 - acc: 0.300 - ETA: 0s - loss: 0.3361 - acc: 0.506 - 0s 217us/step - loss: 0.3404 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 37/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.2901 - acc: 0.550 - ETA: 0s - loss: 0.3351 - acc: 0.513 - 0s 214us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 38/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.2610 - acc: 0.500 - ETA: 0s - loss: 0.3430 - acc: 0.490 - 0s 219us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - ETA: 0s - loss: 0.2573 - acc: 0.600 - ETA: 0s - loss: 0.3254 - acc: 0.516 - 0s 222us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 40/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3928 - acc: 0.450 - ETA: 0s - loss: 0.3496 - acc: 0.487 - 0s 218us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 41/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.1264 - acc: 0.750 - ETA: 0s - loss: 0.3312 - acc: 0.500 - 0s 252us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 42/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.2212 - acc: 0.600 - ETA: 0s - loss: 0.3318 - acc: 0.504 - 0s 248us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 43/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.2517 - acc: 0.550 - ETA: 0s - loss: 0.3528 - acc: 0.492 - 0s 244us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 44/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3610 - acc: 0.600 - ETA: 0s - loss: 0.3336 - acc: 0.503 - 0s 246us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 45/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3670 - acc: 0.550 - ETA: 0s - loss: 0.3297 - acc: 0.515 - 0s 277us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 46/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3988 - acc: 0.500 - ETA: 0s - loss: 0.3191 - acc: 0.515 - 0s 247us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 47/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.2092 - acc: 0.750 - ETA: 0s - loss: 0.3521 - acc: 0.496 - 0s 241us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 48/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3550 - acc: 0.550 - ETA: 0s - loss: 0.3327 - acc: 0.500 - 0s 243us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 49/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.5820 - acc: 0.250 - ETA: 0s - loss: 0.3739 - acc: 0.485 - 0s 311us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 50/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3541 - acc: 0.350 - ETA: 0s - loss: 0.3450 - acc: 0.483 - ETA: 0s - loss: 0.3382 - acc: 0.502 - 0s 339us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 51/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.2209 - acc: 0.650 - ETA: 0s - loss: 0.3392 - acc: 0.496 - 0s 252us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 52/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.2662 - acc: 0.650 - ETA: 0s - loss: 0.3260 - acc: 0.550 - 0s 286us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 53/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3056 - acc: 0.550 - ETA: 0s - loss: 0.3284 - acc: 0.529 - 0s 283us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 54/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.2188 - acc: 0.650 - ETA: 0s - loss: 0.3471 - acc: 0.504 - 0s 266us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 55/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3649 - acc: 0.500 - ETA: 0s - loss: 0.3481 - acc: 0.491 - 0s 273us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 56/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.4244 - acc: 0.450 - ETA: 0s - loss: 0.3261 - acc: 0.511 - 0s 246us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 57/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3340 - acc: 0.550 - ETA: 0s - loss: 0.3170 - acc: 0.530 - 0s 253us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 58/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.2921 - acc: 0.650 - ETA: 0s - loss: 0.3476 - acc: 0.480 - 0s 247us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 59/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.4448 - acc: 0.450 - ETA: 0s - loss: 0.3622 - acc: 0.478 - 0s 239us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 60/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.2223 - acc: 0.600 - ETA: 0s - loss: 0.3265 - acc: 0.507 - 0s 254us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 61/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3449 - acc: 0.400 - ETA: 0s - loss: 0.3484 - acc: 0.489 - 0s 240us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 62/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.2906 - acc: 0.600 - ETA: 0s - loss: 0.3378 - acc: 0.496 - 0s 255us/step - loss: 0.3411 - acc: 0.4986 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 63/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.1202 - acc: 0.700 - ETA: 0s - loss: 0.3704 - acc: 0.473 - 0s 245us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 64/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.1981 - acc: 0.650 - ETA: 0s - loss: 0.3414 - acc: 0.507 - 0s 228us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 65/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.1875 - acc: 0.750 - ETA: 0s - loss: 0.3386 - acc: 0.486 - 0s 233us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 66/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.2486 - acc: 0.550 - ETA: 0s - loss: 0.3412 - acc: 0.492 - 0s 252us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 67/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.4269 - acc: 0.550 - ETA: 0s - loss: 0.3229 - acc: 0.517 - 0s 272us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 68/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3707 - acc: 0.450 - ETA: 0s - loss: 0.3358 - acc: 0.490 - 0s 237us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 69/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3676 - acc: 0.450 - ETA: 0s - loss: 0.3370 - acc: 0.500 - 0s 247us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 70/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.4249 - acc: 0.400 - ETA: 0s - loss: 0.3466 - acc: 0.481 - 0s 260us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 71/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3528 - acc: 0.500 - ETA: 0s - loss: 0.3186 - acc: 0.537 - 0s 260us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 72/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3390 - acc: 0.450 - ETA: 0s - loss: 0.3446 - acc: 0.500 - 0s 299us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 73/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3641 - acc: 0.550 - ETA: 0s - loss: 0.3460 - acc: 0.500 - 0s 227us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 74/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3067 - acc: 0.550 - ETA: 0s - loss: 0.3473 - acc: 0.496 - 0s 225us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 75/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.2716 - acc: 0.600 - ETA: 0s - loss: 0.3336 - acc: 0.500 - 0s 217us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 76/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3096 - acc: 0.500 - ETA: 0s - loss: 0.3452 - acc: 0.493 - 0s 205us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - ETA: 0s - loss: 0.2736 - acc: 0.550 - ETA: 0s - loss: 0.3279 - acc: 0.510 - 0s 228us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 78/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.2405 - acc: 0.650 - ETA: 0s - loss: 0.3455 - acc: 0.492 - 0s 246us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 79/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.4213 - acc: 0.400 - ETA: 0s - loss: 0.3459 - acc: 0.513 - 0s 295us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 80/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.4443 - acc: 0.300 - ETA: 0s - loss: 0.3218 - acc: 0.504 - 0s 305us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 81/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3759 - acc: 0.400 - ETA: 0s - loss: 0.3357 - acc: 0.481 - 0s 295us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 82/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.2501 - acc: 0.650 - ETA: 0s - loss: 0.3513 - acc: 0.491 - 0s 288us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 83/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.4406 - acc: 0.400 - ETA: 0s - loss: 0.3315 - acc: 0.530 - 0s 305us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 84/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.4187 - acc: 0.400 - ETA: 0s - loss: 0.3595 - acc: 0.467 - 0s 244us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 85/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3065 - acc: 0.500 - ETA: 0s - loss: 0.3574 - acc: 0.487 - 0s 259us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 86/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.5922 - acc: 0.300 - ETA: 0s - loss: 0.3652 - acc: 0.487 - 0s 270us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 87/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3008 - acc: 0.600 - ETA: 0s - loss: 0.3313 - acc: 0.522 - 0s 278us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 88/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3037 - acc: 0.550 - ETA: 0s - loss: 0.3634 - acc: 0.483 - 0s 277us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 89/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.5155 - acc: 0.350 - ETA: 0s - loss: 0.3530 - acc: 0.485 - 0s 235us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 90/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.4226 - acc: 0.400 - ETA: 0s - loss: 0.3363 - acc: 0.500 - 0s 254us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 91/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3621 - acc: 0.350 - ETA: 0s - loss: 0.3594 - acc: 0.487 - 0s 277us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 92/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.1900 - acc: 0.650 - ETA: 0s - loss: 0.3542 - acc: 0.486 - 0s 231us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 93/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.1509 - acc: 0.600 - ETA: 0s - loss: 0.3287 - acc: 0.503 - 0s 230us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 94/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.2184 - acc: 0.600 - ETA: 0s - loss: 0.3167 - acc: 0.523 - 0s 218us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 95/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.4214 - acc: 0.400 - ETA: 0s - loss: 0.3326 - acc: 0.507 - 0s 213us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 96/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3652 - acc: 0.550 - ETA: 0s - loss: 0.3319 - acc: 0.512 - 0s 225us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 97/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3703 - acc: 0.550 - ETA: 0s - loss: 0.3328 - acc: 0.513 - 0s 214us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 98/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.2054 - acc: 0.550 - ETA: 0s - loss: 0.3220 - acc: 0.510 - 0s 235us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 99/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3224 - acc: 0.450 - ETA: 0s - loss: 0.3613 - acc: 0.470 - 0s 255us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n",
      "Epoch 100/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.2607 - acc: 0.600 - ETA: 0s - loss: 0.3494 - acc: 0.500 - 0s 320us/step - loss: 0.3401 - acc: 0.5014 - val_loss: 0.3721 - val_acc: 0.4945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a1f8ad0a90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train,y=y_train,batch_size=20,epochs=100,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导自写工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../utils')\n",
    "import to_pickle as pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(u'E:\\\\a_school\\智能运维\\code\\朱嘉业-1352953')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import util"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
