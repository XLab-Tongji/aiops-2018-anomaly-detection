{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import util\n",
    "import keras as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "# import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainData = pd.read_csv('data/train.csv')\n",
    "trainData = pd.read_csv('data/046ec29ddf80d62e.csv')\n",
    "#testData = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8784, 15)\n"
     ]
    }
   ],
   "source": [
    "# here is for feature engineering data process\n",
    "data = np.array(trainData)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainData['timestamp'] = pd.to_datetime(trainData['timestamp'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value    0.009107\n",
      "label    0.009107\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data = trainData[trainData['KPI ID']=='046ec29ddf80d62e']\n",
    "data = data.set_index('timestamp')\n",
    "data = data.drop(columns=['KPI ID'])\n",
    "print(data[data['label']==1].count()/data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocessing.minmax_scale(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitInputOutput(data,sequence_length, feature_column_start=0, feature_column_end=-1):\n",
    "    trainInput = []\n",
    "    trainOutput = []\n",
    "    for index in range(len(data) - sequence_length):\n",
    "        trainInput.append(data[index: index + sequence_length,feature_column_start:feature_column_end])\n",
    "        trainOutput.append(data[index+sequence_length-1,-1])\n",
    "    return trainInput, trainOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainInput, trainOutput = splitInputOutput(data,sequence_length=30,feature_column_start=0,feature_column_end=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8754, 30, 14)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(trainInput).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8754,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(trainOutput).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oversample times:  53\n",
      "Positive sample ratio: 0.33246113590888104\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "暴力重复过采样至正负1:1，不可取，只做示意\n",
    "'''\n",
    "idxRecord = []\n",
    "for idx in range(len(trainOutput)):\n",
    "    if trainOutput[idx] == 1:\n",
    "        idxRecord.append(idx)\n",
    "overSampleTimes = int(int(len(trainInput)/len(idxRecord) -2)/2)\n",
    "print('oversample times: ', overSampleTimes)\n",
    "for i in range(overSampleTimes):\n",
    "    for idx in idxRecord:\n",
    "        trainInput.append(trainInput[idx])\n",
    "        trainOutput.append(trainOutput[idx])\n",
    "PositiveCount = 0\n",
    "for idx in range(len(trainOutput)):\n",
    "    if trainOutput[idx] == 1:\n",
    "        PositiveCount += 1\n",
    "print('Positive sample ratio:',PositiveCount/len(trainInput))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildModel(input_shape, drop=0.5, lr=1e-2, loss='mse', metrics=[]):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(64,return_sequences=True), input_shape=input_shape))\n",
    "    model.add(Dropout(drop))\n",
    "    model.add(Bidirectional(LSTM(128,return_sequences=True)))\n",
    "    model.add(Dropout(drop))\n",
    "    model.add(Bidirectional(LSTM(64,return_sequences=False)))\n",
    "    model.add(Dense(units=256,activation='relu'))\n",
    "    model.add(Dropout(drop))\n",
    "    model.add(Dense(units=1,activation='sigmoid'))\n",
    "    c = optimizers.adam(lr = lr)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=c, metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.array(trainInput)\n",
    "trainY = np.array(trainOutput)\n",
    "trainX = K.utils.normalize(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(trainX, trainY, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10395 samples, validate on 2599 samples\n",
      "Epoch 1/20\n",
      "10395/10395 [==============================] - 46s 4ms/step - loss: 0.3241 - acc: 0.8920 - val_loss: 0.1879 - val_acc: 0.9481\n",
      "Epoch 2/20\n",
      "10395/10395 [==============================] - 37s 4ms/step - loss: 0.1762 - acc: 0.9461 - val_loss: 0.1658 - val_acc: 0.9519\n",
      "Epoch 3/20\n",
      "10395/10395 [==============================] - 41s 4ms/step - loss: 0.0672 - acc: 0.9720 - val_loss: 0.0025 - val_acc: 0.9992\n",
      "Epoch 4/20\n",
      "10395/10395 [==============================] - 40s 4ms/step - loss: 0.0192 - acc: 0.9942 - val_loss: 8.9368e-04 - val_acc: 1.0000\n",
      "Epoch 5/20\n",
      "10395/10395 [==============================] - 40s 4ms/step - loss: 0.0248 - acc: 0.9926 - val_loss: 0.6335 - val_acc: 0.9130\n",
      "Epoch 6/20\n",
      "10395/10395 [==============================] - 41s 4ms/step - loss: 0.0810 - acc: 0.9727 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "10395/10395 [==============================] - 40s 4ms/step - loss: 0.0073 - acc: 0.9984 - val_loss: 2.6143e-04 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "10395/10395 [==============================] - 40s 4ms/step - loss: 0.0044 - acc: 0.9988 - val_loss: 4.9351e-04 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "10395/10395 [==============================] - 41s 4ms/step - loss: 0.0046 - acc: 0.9987 - val_loss: 1.3069e-04 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "10395/10395 [==============================] - 41s 4ms/step - loss: 0.0740 - acc: 0.9826 - val_loss: 0.0025 - val_acc: 0.9996\n",
      "Epoch 11/20\n",
      "10395/10395 [==============================] - 41s 4ms/step - loss: 0.0528 - acc: 0.9822 - val_loss: 0.0289 - val_acc: 0.9885\n",
      "Epoch 12/20\n",
      "10395/10395 [==============================] - 41s 4ms/step - loss: 0.0331 - acc: 0.9892 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "10395/10395 [==============================] - 40s 4ms/step - loss: 0.0100 - acc: 0.9969 - val_loss: 4.4376e-04 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "10395/10395 [==============================] - 41s 4ms/step - loss: 0.0030 - acc: 0.9993 - val_loss: 4.1770e-04 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "10395/10395 [==============================] - 35s 3ms/step - loss: 0.0087 - acc: 0.9975 - val_loss: 1.7692e-04 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "10395/10395 [==============================] - 40s 4ms/step - loss: 0.0035 - acc: 0.9991 - val_loss: 4.1628e-05 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "10395/10395 [==============================] - 35s 3ms/step - loss: 0.0014 - acc: 0.9997 - val_loss: 7.2430e-05 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      " 7552/10395 [====================>.........] - ETA: 9s - loss: 0.0011 - acc: 0.9997  "
     ]
    }
   ],
   "source": [
    "model = buildModel(input_shape=(None,14),drop=0.5,\\\n",
    "                        lr=1e-2, loss='binary_crossentropy',metrics=['acc'])\n",
    "# save the best model here (for future use)\n",
    "#model_checkpoint = ModelCheckpoint(new_save_model_name,monitor='val_my_iou_metric_2', \n",
    "#                                       mode = 'max', save_best_only=True, verbose=1)\n",
    "# reduce the learning rate to get further progress\n",
    "reduce_lr = ReduceLROnPlateau(monitor='acc', mode = 'max',\\\n",
    "                              factor=0.5, patience=5, min_lr=0.0001, verbose=1)\n",
    "# early stopping to avoid overfitting\n",
    "#early_stopping = EarlyStopping(monitor='acc', mode = 'max', patience=20, verbose=1)\n",
    "epochs = 20\n",
    "batch_size = 128\n",
    "history = model.fit(x_train, y_train,\n",
    "                    validation_data=[x_valid, y_valid], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    #callbacks=[ model_checkpoint], \n",
    "                    verbose=1)\n",
    "#plot_history(history,'my_iou_metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
